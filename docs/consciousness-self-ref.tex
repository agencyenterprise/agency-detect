\documentclass[12pt]{article}
\usepackage{times}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage{float}
\usepackage[backend=bibtex,style=authoryear]{biblatex}
\usepackage[colorlinks=true,citecolor=blue,urlcolor=blue,linkcolor=black]{hyperref}
\addbibresource{refs.bib}

\title{Thou art rainbow. Consciousness as a Self-Referential Physical Process}
\author{Gunnar Zarncke\\AE Studio}
\date{September 2, 2025}

\begin{document}

\maketitle

\begin{quote}
\emph{You're not a ghost in the machine; you're a rainbow in the noisy drizzle of perception.}
\end{quote}

\begin{abstract}
The ``hard problem'' of consciousness is often framed as the explanatory gap between physical processes and subjective experience. 
We argue that the gap dissolves once consciousness is treated as a self-referential physical process whose special character 
derives from recursion and whose phenomenology is partially illusory, akin to optical appearances such as rainbows. 
Infinite regress arguments show that positing an inner observer is unstable; 
what remains is a deflationary realism in which consciousness is real and special, but not ontologically separate.
\end{abstract}

\section{Introduction}

Chalmers (1996) famously distinguished the ``easy problems'' of consciousness (information integration, attention, reportability) 
from the ``hard problem'' of explaining why there is ``something it is like.'' 
Critics of reductive approaches insist that the datum of experience is ineliminable: 
even if consciousness were an illusion, it must be an illusion \emph{experienced} by something \parencite{Chalmers1996,Strawson2006}. 

Illusionists, such as \textcite{Dennett1991} and \textcite{Frankish2016}, argue that this datum is itself a product of cognitive architecture: consciousness only \emph{seems} irreducible 
because our introspective systems misrepresent their own operations. Yet this line is often accused of nihilism. 

The synthesis proposed here accepts the insight of illusionism while rejecting nihilism: 
consciousness is a physical process whose self-referential form makes it \emph{appear} as if there were a Cartesian inner glow. 
Like a rainbow, it is real but not fundamental; the illusion lies in how it presents itself, not in its existence.

To avoid ambiguity, we distinguish consciousness from related notions. 
By \emph{consciousness} we mean the phenomenological self-appearance 
generated by self-modeling. This is narrower than general 
awareness, broader than mere sentience \parencite{Singer2011} (capacity for pleasure and pain), 
and not identical with intelligence or reportability \parencite{Dehaene2014}. 

\section{Descartes: Rainbow and Mind}

\begin{figure}[H]
\centering
\includegraphics[width=0.55\textwidth]{Descartes_Rainbow.png}
\hfill
\includegraphics[width=0.35\textwidth]{descartes_sehen.jpg}
\caption{Left: Descartes' geometric analysis of the rainbow from \emph{Les Météores} (1637), 
showing how light refracts through water droplets to create the optical phenomenon. 
Right: \textcite{descartes1996meditations} diagram of vision and perception, 
showing how light rays enter the eyes, transmit mechanical signals through the optic nerves, and converge at the pineal gland, the 
supposed seat of the soul, where bodily mechanism and thinking substance interact.}
\label{fig:descartes-rainbow-mind}
\end{figure} 

Descartes investigated both consciousness and the rainbow. 
In \textcite{Descartes1641}, he famously grounded certainty in the 
\emph{cogito}, treating the mind as a self-evident inner datum beyond the scope of 
physical explanation. Yet already in \textcite{Descartes1637}, he gave 
one of the first physical-geometrical accounts of the rainbow: an optical law 
derived from light refracting through droplets, with no hidden essence. 

This juxtaposition is instructive. Descartes naturalized the rainbow while 
mystifying the mind. With modern understanding of how the brain learns, 
we can take the strategy he deployed in optics to it's natural conclusion: 
conscious experience, like the rainbow, is real and law-governed but not 
ontologically primitive.

\section{Self-Perception and Rarity}

Most physical processes are non-reflexive. A pendulum swings; a chemical reaction propagates. 
There are even pyhsical processes that are self-similar, such as coast lines, 
self-propagating, such as cells, or even self-referencing, such as gene sequences, or Gödel sentences
By contrast, consciousness is recursive in the self-modeling and self-perceiving sense: 
the system models the world and also models itself as an observer within that world. 

\textcite{Metzinger2003} calls this the \emph{phenomenal self-model}, 
while \textcite{Graziano2013} characterizes it as an \emph{attention schema}. 

We notice that such self-modeling and self-perceiving systems are rare in nature 
due to the required computational and structural complexity. 

When recursion is present it produces special-seeming phenomena:
Gödelian undecidability, compilers compiling themselves, or cellular replication already inspire awe.
How much more so are cognitive systems asserting their own existence?
Thus, consciousness \emph{feels} exceptional because it \emph{is} a rare phenomenon: 
It a process that is recursively locked on itself. 
But not because it is metaphysically distinct.

\section{The Illusion Component}

Illusionism correctly notes that consciousness misrepresents itself. 
Just as the brain constructs a visual field without access to its underlying neuronal computations, 
so it constructs a sense of ``inner presence'' without access to the mechanisms generating that representation. 
\textcite{Dennett1991} calls this the rejection of the ``Cartesian Theater.'' 

Illusion here must not be confused with nonexistence. 
To call consciousness partly illusory is to say its mode of 
presentation misrepresents its own basis. The glow is not 
fundamental, but the process producing it is real. 
This avoids both eliminativist nihilism and dualist reification.

\textcite{Yudkowsky2015Algorithm} offers a complementary insight: introspection itself is algorithmic, and algorithms have characteristic failure modes. 
If the brain implicitly models itself with a central categorization node, the subjective feeling of an \emph{unanswered question}, 
the hanging central node, can persist even after all relevant information is integrated. From the inside, this feels like an inconsistency. 
The ``hard problem'' may thus be the phenomenological shadow cast by the brain's cognitive architecture or its during-lifetime learning, 
a structural feature rather than a metaphysical gap.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{blegg3-yudkowsky.png}
\caption{Yudkowsky's illustration of how algorithms can systematically produce the feeling of an unanswered question even when all relevant information has been processed. The ``blegg'' categorization demonstrates how central nodes in cognitive architecture can create persistent subjective inconsistencies.}
\label{fig:yudkowsky-blegg}
\end{figure} 

Yet the illusion is partial: there is indeed a real process generating the misrepresentation. 
To deny this would be like denying the existence of a rainbow because it is not a material arch. 
The rainbow analogy \parencite{Dennett1991,Blackmore2004} is instructive: 
the phenomenon is lawful and real, but not ontologically primitive. Consciousness belongs to this same category. 

\section{Infinite Regress and the Observer}

The demand for an inner witness (``something must be experiencing something'') leads inexorably to regress. 
The critic's insistence that "something must be experiencing 
something" is powerful but unstable. Taken literally, it requires 
an infinite regress of observers. Our argument does not deny 
experience but locates it in self-referential process rather 
than a metaphysical subject.
If an inner self must observe experience, what observes the self? 
\textcite{Ryle1949} already flagged this as the fallacy of the ``ghost in the machine.'' 
By recognizing consciousness as a process rather than a locus, the regress dissolves. 

The rainbow again clarifies: one need not posit a ghostly arch to explain the appearance; 
it suffices to specify the physical conditions under which an observer \emph{would} see it. 
Similarly, we can model the conditions under which a brain \emph{would} 
produce the self-appearance of being conscious.
Positing a hidden observer adds no explanatory power.

\section*{Falsifiable Predictions}

If consciousness is a self-referential physical process
emerging from recursive self-models under a physically bounded agent, 
then several falsifiable empirical consequences follow.

\begin{enumerate}
    \item \textbf{Recursion requirement.} Conscious phenomenology should only arise in
    systems whose internal states model both the world and their own internal
    dynamics as an observer within that world. Neural or artificial systems that lack
    such recursive architectures should not report or behave as though they experience
    an ``inner glow.''

    \item \textbf{Opacity of introspection.} Conscious systems should systematically
    misrepresent their own generative processes. Introspective access must be lossy:
    subjects report stable, unified fields (visual, affective, cognitive) while the
    underlying implementation remains hidden. Experimental manipulations that
    increase transparency of underlying mechanisms should not increase but rather
    degrade phenomenology.

    \item \textbf{Dangling-node phenomenology.} Recursive self-models should include
    variables that are globally referenced but not decomposed into lower-level
    features. This structural bottleneck predicts the persistent subjective impression
    of an unanswered question, i.e.\ the felt ``hard problem.'' Systems engineered
    without such bottlenecks should display functional competence without reporting
    ineffability.

    \item \textbf{Lesion-induced distortions.} Damage to cortical regions that support
    self-referential recursion (e.g.\ parietal or prefrontal hubs) should yield not only
    local perceptual deficits but systematic distortions of global self-models (e.g.\
    warped spatial awareness, anosognosia), rather than mere filling-in.

    \item \textbf{Depth of recursion.} Consciousness should scale with recursive depth.
    First-order world models suffice for adaptive control, but only systems that
    implement at least second-order predictions (modeling their own modeling) should
    display reportable phenomenology. Empirically, metacognitive capacity should
    correlate with subjective richness.

    \item \textbf{Process not locus.} There should be no unique anatomical or algorithmic
    ``theater'' in which consciousness resides. Instead, distributed self-referential
    loops should be necessary. Interventions targeting a single hub (e.g.\ thalamus)
    may enable or disable global recursion, but the phenomenology should not be localized
    to that hub alone.

    \item \textbf{Observer-relativity.} Consciousness, like a rainbow, should be
    observer-dependent, or rather allow for arbitrary conceptions of observers. 
    Manipulations that alter the structural perspective of the system 
    (e.g.\ body-swap illusions, temporally perturbed sensorimotor feedback, or
    altered interoception) should correspondingly shift or dissolve the felt locus of
    presence.
\end{enumerate}

\section*{Tentative Evidence}

Several empirical domains already provide evidence relevant to the proposed predictions:

\begin{enumerate}
\item \textbf{Thalamic control.} Bilateral lesions to central thalamic nuclei can abolish consciousness, while deep 
brain stimulation (DBS) partially restores responsiveness in minimally conscious state patients \parencite{schiff2007_behavioural}. 
In anesthetized primates, thalamic DBS reinstates cortical dynamics of wakefulness \parencite{redinbaugh2020_thalamus}. 
This supports a distributed, gateway-mediated rather than theater-like architecture (Pred.\ 6).

\item \textbf{Lesion-induced distortions.} Parietal and temporo-parietal damage yields global distortions of space and body 
(neglect, anosognosia, metamorphopsia) rather than simple filling-in \parencite{venkatesan2015_anosognosia,baier2007_somatoparaphrenia}, 
consistent with recursive model deformation (Pred.\ 4).

\item \textbf{Split and unified selves.} Callosotomy can fractionate awareness into parallel streams \parencite{gazzaniga2005_forty}, 
while hemispherectomy re-centers unity in the remaining hemisphere \parencite{li2020_hemispherectomy}, showing that consciousness depends 
on large-scale recurrent integration rather than a single locus (Pred.\ 1, 6).

\item \textbf{Metacognitive depth.} Higher metacognitive sensitivity correlates with vividness and stability of reported 
experience \parencite{fleming2014_how,morales2018_domain}, supporting the claim that recursion depth scales phenomenology (Pred.\ 1, 5).

\item \textbf{Observer-relativity.} Body-swap illusions, delayed visuomotor feedback, and interoceptive manipulations lawfully shift or 
dissolve the felt locus of presence \parencite{ehrsson2004_rubber,blanke2012_multisensory}. 
Meditation practitioners also report altered self-location or loss of self \parencite{milliere2018psychedelics,lindahl2019varieties}.
These confirm perspectival dependence (Pred.\ 7).

\item \textbf{Mental action.} Covert attention and belief updates modulate conscious contents in rivalry, change blindness, and 
motion-induced blindness without new sensory input \parencite{frassle2014_binocular,koch2016_neural}, consistent with the role of active sampling (Pred.\ 3).
\end{enumerate}

\paragraph{Comparison}
IIT \parencite{oizumi2014_iit,tononi2014_phi} is supported on lesion-induced distortions but overstates the role of quiescent elements. 
Higher-order thought theories \parencite{rosenthal2005_consciousness} underpredict metacognitive and perspectival effects. 
Attention-based theories \parencite{prinz2012_attended} are supported on attentional and belief updates but do not explain persistent ineffability from recursive bottlenecks. 
Our self-referential account thus combines IIT's structural sensitivity with attention-based policy sensitivity, 
grounded in recursive self-models. 

In a forthcoming paper, we will argue that this recursive self-modeling can be formalized by specifying agents as Markov blankets \parencite{friston2010_free,parr2022_active}.

\section{Conclusion}

Consciousness is not an ontological primitive but a physical process of recursive self-modeling. 
Its rarity derives from the rarity of natural recursions; its sense of ineffable glow derives from partial illusion; 
the regress dissolves once the inner observer is dropped. 
In this framing, the ``hard problem'' is revealed not as an intractable metaphysical mystery but as a cognitive 
mirage generated by self-referential architecture. 
Yudkowsky's central-node argument suggests why the mirage is so compelling: 
algorithms can systematically produce the \emph{feeling} of a remainder even when nothing remains to explain. 
Consciousness is to physical process what the rainbow is to optics: 
real, lawful, misdescribed from the inside, and not ontologically sui generis.

\begin{quote}
\emph{Thou art rainbow.}
\end{quote}

Or as Descartes might say:

\begin{quote}
\emph{Cogito, ergo ut iris.}
\end{quote}

\noindent I am thanking the reviewers Cameron Berg, Jonas Hallgren, and Chris Pang for their helpful comments. 
A special thanks goes to Julia Harfensteller. Without her meditation teaching, I would have been able to form the insights behind this paper.

\printbibliography

\end{document}
